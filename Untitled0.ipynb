{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOhYwGL9lEzsBjMPN7l1KeQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jashwant16300/English-Manipuri-Translation-Analysis/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "6q-F6TG0pmQX"
      },
      "outputs": [],
      "source": [
        "# Install Hugging Face transformers, evaluation metrics, and translation tools\n",
        "!pip install -q transformers torch pandas sacrebleu sentencepiece deep-translator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Creating a small test dataset (Parallel Corpus)\n",
        "# We include English, and the correct human translations in Bengali script & Meetei Mayek\n",
        "data = {\n",
        "    \"English\": [\n",
        "        \"I am a student.\",\n",
        "        \"What is your name?\",\n",
        "        \"Education is very important.\",\n",
        "        \"Where are you going?\"\n",
        "    ],\n",
        "    \"True_Manipuri_Bengali\": [\n",
        "        \"ঐ মহৈরোই অমনি।\",\n",
        "        \"নমিং করি কৌবগে?\",\n",
        "        \"লাইরিক তম্বা অসি য়াম্না মরু ওই।\",\n",
        "        \"নহাক কদাইদা চৎকদবা?\"\n",
        "    ],\n",
        "    \"True_Manipuri_Meetei\": [\n",
        "        \"ꯑꯩ ꯃꯍꯩꯔꯣꯏ ꯑꯃꯅꯤ꯫\",\n",
        "        \"ꯅꯃꯤꯡ ꯀꯔꯤ ꯀꯧꯕꯒꯦ?\",\n",
        "        \"ꯂꯥꯏꯔꯤꯛ ꯇꯝꯕꯥ ꯑꯁꯤ ꯌꯥꯝꯅꯥ ꯃꯔꯨ ꯑꯣꯏ꯫\",\n",
        "        \"ꯅꯍꯥꯛ ꯀꯗꯥꯏꯗꯥ ꯆꯠꯀꯗꯕꯥ?\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "display(df)"
      ],
      "metadata": {
        "id": "D7Hq4Oh3qSup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "print(\"Loading NLLB Model...\")\n",
        "model_name = \"facebook/nllb-200-distilled-600M\"\n",
        "\n",
        "# We use use_fast=False to ensure compatibility, or we use convert_tokens_to_ids\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = model.to(device)\n",
        "print(f\"Model loaded on {device}!\")\n",
        "\n",
        "# Corrected Function to translate text\n",
        "def translate_nllb(text, target_lang_code):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # FIX: Use convert_tokens_to_ids instead of lang_code_to_id\n",
        "    target_lang_id = tokenizer.convert_tokens_to_ids(target_lang_code)\n",
        "\n",
        "    translated_tokens = model.generate(\n",
        "        **inputs,\n",
        "        forced_bos_token_id=target_lang_id,\n",
        "        max_length=100\n",
        "    )\n",
        "    return tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n",
        "\n",
        "# 1. Translate to Manipuri (Bengali Script)\n",
        "print(\"Translating to Bengali Script...\")\n",
        "df['NLLB_Pred_Bengali'] = df['English'].apply(lambda x: translate_nllb(x, \"mni_Beng\"))\n",
        "\n",
        "# 2. Translate to Manipuri (Meetei Mayek Script)\n",
        "print(\"Translating to Meetei Mayek...\")\n",
        "df['NLLB_Pred_Meetei'] = df['English'].apply(lambda x: translate_nllb(x, \"mni_Mtei\"))\n",
        "\n",
        "print(\"Translation Complete! Here are the results:\")\n",
        "display(df[['English', 'NLLB_Pred_Bengali', 'NLLB_Pred_Meetei']])"
      ],
      "metadata": {
        "id": "sd-3D3WTqvHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "print(\"Running Google Translate Baseline...\")\n",
        "\n",
        "# Function for Google Translate\n",
        "def translate_google(text, target_lang):\n",
        "    try:\n",
        "        return GoogleTranslator(source='en', target=target_lang).translate(text)\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "# Google Translate uses 'bn' for Bengali language, and 'mni-Mtei' for Meetei Mayek\n",
        "df['Google_Pred_Bengali'] = df['English'].apply(lambda x: translate_google(x, 'bn'))\n",
        "df['Google_Pred_Meetei'] = df['English'].apply(lambda x: translate_google(x, 'mni-Mtei'))\n",
        "\n",
        "print(\"\\n Master Comparative Table:\")\n",
        "# Reordering columns to show them side-by-side for easy comparison\n",
        "final_columns = [\n",
        "    'English',\n",
        "    'True_Manipuri_Bengali', 'NLLB_Pred_Bengali', 'Google_Pred_Bengali',\n",
        "    'True_Manipuri_Meetei', 'NLLB_Pred_Meetei', 'Google_Pred_Meetei'\n",
        "]\n",
        "display(df[final_columns])"
      ],
      "metadata": {
        "id": "lcdEvB566gCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sacrebleu\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "print(\"Calculating BLEU Scores and Generating Graph...\\n\")\n",
        "\n",
        "# Format the \"True\" original translations for SacreBLEU (must be list of lists)\n",
        "refs_bengali = [df['True_Manipuri_Bengali'].tolist()]\n",
        "refs_meetei = [df['True_Manipuri_Meetei'].tolist()]\n",
        "\n",
        "# Calculate BLEU Scores for Bengali Script\n",
        "bleu_nllb_beng = sacrebleu.corpus_bleu(df['NLLB_Pred_Bengali'].tolist(), refs_bengali).score\n",
        "bleu_google_beng = sacrebleu.corpus_bleu(df['Google_Pred_Bengali'].tolist(), refs_bengali).score\n",
        "\n",
        "# Calculate BLEU Scores for Meetei Mayek\n",
        "bleu_nllb_meetei = sacrebleu.corpus_bleu(df['NLLB_Pred_Meetei'].tolist(), refs_meetei).score\n",
        "bleu_google_meetei = sacrebleu.corpus_bleu(df['Google_Pred_Meetei'].tolist(), refs_meetei).score\n",
        "\n",
        "# Print Exact Scores\n",
        "print(f\"Bengali Script -> NLLB: {bleu_nllb_beng:.2f} | Google: {bleu_google_beng:.2f}\")\n",
        "print(f\"Meetei Mayek   -> NLLB: {bleu_nllb_meetei:.2f} | Google: {bleu_google_meetei:.2f}\\n\")\n",
        "\n",
        "# --- Draw the Comparative Grouped Bar Chart ---\n",
        "labels = ['Bengali Script', 'Meetei Mayek Script']\n",
        "nllb_scores = [bleu_nllb_beng, bleu_nllb_meetei]\n",
        "google_scores = [bleu_google_beng, bleu_google_meetei]\n",
        "\n",
        "x = np.arange(len(labels))  # the label locations\n",
        "width = 0.35  # the width of the bars\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(9, 6))\n",
        "rects1 = ax.bar(x - width/2, nllb_scores, width, label='NLLB-200 (600M)', color='#1f77b4')\n",
        "rects2 = ax.bar(x + width/2, google_scores, width, label='Google Translate (Baseline)', color='#ff7f0e')\n",
        "\n",
        "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "ax.set_ylabel('BLEU Score (Higher is Better)', fontsize=12)\n",
        "ax.set_title('Comparative Analysis: NLLB vs Google Translate', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels, fontsize=12)\n",
        "ax.legend()\n",
        "\n",
        "# Attach a text label above each bar displaying its height (the exact score)\n",
        "for rect in rects1 + rects2:\n",
        "    height = rect.get_height()\n",
        "    ax.annotate(f'{height:.2f}',\n",
        "                xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                xytext=(0, 3),  # 3 points vertical offset\n",
        "                textcoords=\"offset points\",\n",
        "                ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "PMnr5Wr98wHq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}